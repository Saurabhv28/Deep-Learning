{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dropout Regularization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dropout Regularization:\n",
        "1. A new hyperparameter is introduced that specifies the probability at which outputs of the layer are dropped out, or inversely, the probability at which outputs of the layer are retained.\n",
        "2. Dropout is implemented per-layer in a neural network. Dropout may be implemented on any or all hidden layers in the network as well as the visible or input layer. It is not used on the output layer.\n",
        "3. A common value is a probability of 0.5 for retaining the output of each node in a hidden layer and a value close to 1.0, such as 0.8, for retaining inputs from the visible layer."
      ],
      "metadata": {
        "id": "XLwTEc_u3GN5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORy8fPh9q9V_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "01axooIktZBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70qEP-0ZtZEg",
        "outputId": "981306ba-9944-4487-a0d7-25c7745a911d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Code Basics Deep Learning/sonar.all-data', header = None)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "d1F4dDTLt1z5",
        "outputId": "3a412a47-14e1-4ced-ece5-06d853664efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d8d87037-190c-4a3f-806c-a84d5c28f777\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.1609</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.2238</td>\n",
              "      <td>0.0645</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>0.2273</td>\n",
              "      <td>0.3100</td>\n",
              "      <td>0.2999</td>\n",
              "      <td>0.5078</td>\n",
              "      <td>0.4797</td>\n",
              "      <td>0.5783</td>\n",
              "      <td>0.5071</td>\n",
              "      <td>0.4328</td>\n",
              "      <td>0.5550</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.7104</td>\n",
              "      <td>0.8080</td>\n",
              "      <td>0.6791</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>0.1307</td>\n",
              "      <td>0.2604</td>\n",
              "      <td>0.5121</td>\n",
              "      <td>0.7547</td>\n",
              "      <td>0.8537</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>0.6692</td>\n",
              "      <td>0.6097</td>\n",
              "      <td>0.4943</td>\n",
              "      <td>0.2744</td>\n",
              "      <td>0.0510</td>\n",
              "      <td>0.2834</td>\n",
              "      <td>0.2825</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.2641</td>\n",
              "      <td>0.1386</td>\n",
              "      <td>0.1051</td>\n",
              "      <td>0.1343</td>\n",
              "      <td>0.0383</td>\n",
              "      <td>0.0324</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.4918</td>\n",
              "      <td>0.6552</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>0.7797</td>\n",
              "      <td>0.7464</td>\n",
              "      <td>0.9444</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8874</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>0.7818</td>\n",
              "      <td>0.5212</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.3957</td>\n",
              "      <td>0.3914</td>\n",
              "      <td>0.3250</td>\n",
              "      <td>0.3200</td>\n",
              "      <td>0.3271</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.4423</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.3788</td>\n",
              "      <td>0.2947</td>\n",
              "      <td>0.1984</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.1306</td>\n",
              "      <td>0.4182</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1840</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.0621</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0530</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.0409</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.5544</td>\n",
              "      <td>0.5320</td>\n",
              "      <td>0.6479</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>0.6759</td>\n",
              "      <td>0.7551</td>\n",
              "      <td>0.8929</td>\n",
              "      <td>0.8619</td>\n",
              "      <td>0.7974</td>\n",
              "      <td>0.6737</td>\n",
              "      <td>0.4293</td>\n",
              "      <td>0.3648</td>\n",
              "      <td>0.5331</td>\n",
              "      <td>0.2413</td>\n",
              "      <td>0.5070</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.6036</td>\n",
              "      <td>0.8514</td>\n",
              "      <td>0.8512</td>\n",
              "      <td>0.5045</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.2709</td>\n",
              "      <td>0.4232</td>\n",
              "      <td>0.3043</td>\n",
              "      <td>0.6116</td>\n",
              "      <td>0.6756</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.4719</td>\n",
              "      <td>0.4647</td>\n",
              "      <td>0.2587</td>\n",
              "      <td>0.2129</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.0176</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.0744</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0106</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>0.1992</td>\n",
              "      <td>0.0184</td>\n",
              "      <td>0.2261</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>0.0693</td>\n",
              "      <td>0.2281</td>\n",
              "      <td>0.4060</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.2741</td>\n",
              "      <td>0.3690</td>\n",
              "      <td>0.5556</td>\n",
              "      <td>0.4846</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.5334</td>\n",
              "      <td>0.5256</td>\n",
              "      <td>0.2520</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.3559</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.7340</td>\n",
              "      <td>0.6120</td>\n",
              "      <td>0.3497</td>\n",
              "      <td>0.3953</td>\n",
              "      <td>0.3012</td>\n",
              "      <td>0.5408</td>\n",
              "      <td>0.8814</td>\n",
              "      <td>0.9857</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.6121</td>\n",
              "      <td>0.5006</td>\n",
              "      <td>0.3210</td>\n",
              "      <td>0.3202</td>\n",
              "      <td>0.4295</td>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1576</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0294</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>0.4152</td>\n",
              "      <td>0.3952</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.4135</td>\n",
              "      <td>0.4528</td>\n",
              "      <td>0.5326</td>\n",
              "      <td>0.7306</td>\n",
              "      <td>0.6193</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4636</td>\n",
              "      <td>0.4148</td>\n",
              "      <td>0.4292</td>\n",
              "      <td>0.5730</td>\n",
              "      <td>0.5399</td>\n",
              "      <td>0.3161</td>\n",
              "      <td>0.2285</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7262</td>\n",
              "      <td>0.4724</td>\n",
              "      <td>0.5103</td>\n",
              "      <td>0.5459</td>\n",
              "      <td>0.2881</td>\n",
              "      <td>0.0981</td>\n",
              "      <td>0.1951</td>\n",
              "      <td>0.4181</td>\n",
              "      <td>0.4604</td>\n",
              "      <td>0.3217</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.1979</td>\n",
              "      <td>0.2444</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.0841</td>\n",
              "      <td>0.0692</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8d87037-190c-4a3f-806c-a84d5c28f777')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8d87037-190c-4a3f-806c-a84d5c28f777 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8d87037-190c-4a3f-806c-a84d5c28f777');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       0       1       2       3       4   ...      56      57      58      59  60\n",
              "0  0.0200  0.0371  0.0428  0.0207  0.0954  ...  0.0180  0.0084  0.0090  0.0032   R\n",
              "1  0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044   R\n",
              "2  0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078   R\n",
              "3  0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117   R\n",
              "4  0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094   R\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YytAH-EuluJ",
        "outputId": "781bcc70-938a-49ae-bad2-51cf16ef8fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(208, 61)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[60].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXkyGfituovA",
        "outputId": "45c801b6-3756-4e11-dc4b-828aa9e68f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "M    111\n",
              "R     97\n",
              "Name: 60, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df[60].replace({'M': 0, 'R': 1}, inplace = True) "
      ],
      "metadata": {
        "id": "co49v4PrvRAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(60, axis = 'columns')\n",
        "y = df[60]"
      ],
      "metadata": {
        "id": "YMfwX12dvBxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alternate way to assign 0 and 1:\n",
        "y = pd.get_dummies(y, drop_first = True)\n",
        "y.sample(5) # 'M': 0, 'R': 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CPoK2qeivNXI",
        "outputId": "99980d72-6dc0-413a-ec0a-8fc2555d20db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f393ad39-c46a-42bc-86c6-1acdcbb992d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f393ad39-c46a-42bc-86c6-1acdcbb992d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f393ad39-c46a-42bc-86c6-1acdcbb992d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f393ad39-c46a-42bc-86c6-1acdcbb992d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     R\n",
              "82   1\n",
              "0    1\n",
              "137  0\n",
              "199  0\n",
              "64   1"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDyiK3L5wv0A",
        "outputId": "705ed33d-f4e6-47de-c7e5-af6608b96c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "R\n",
              "0    111\n",
              "1     97\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)"
      ],
      "metadata": {
        "id": "K6XJRT-vwzto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Oh3FA05xF2Y",
        "outputId": "9e450928-8251-4b37-a050-e76d1e4218e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(156, 60)\n",
            "(52, 60)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "eE7MG8mpxJjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "        keras.layers.Dense(60, input_dim = 60, activation = 'relu'),\n",
        "        keras.layers.Dense(30, activation = 'relu'),\n",
        "        keras.layers.Dense(15, activation = 'relu'),\n",
        "        keras.layers.Dense(1, activation = 'sigmoid')                          \n",
        "])\n",
        "\n",
        "model.compile(loss= 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hFUBw9XVxSUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs = 100, batch_size = 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcZYuYzmxSV2",
        "outputId": "54891b1a-54a9-4ea2-d6fa-2fa742900133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 2ms/step - loss: 0.6667 - accuracy: 0.6474\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.6538\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.7308\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.7179\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7244\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7756\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7564\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.8013\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7885\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8526\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.7756\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8333\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8077\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8846\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8590\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8846\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8846\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.8846\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8718\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2790 - accuracy: 0.8782\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2553 - accuracy: 0.9295\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.9167\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.8782\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.8718\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.9167\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2056 - accuracy: 0.9359\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9359\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.9359\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9423\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9423\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1547 - accuracy: 0.9487\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.9679\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9615\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9744\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1123 - accuracy: 0.9744\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1053 - accuracy: 0.9808\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9615\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9872\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0942 - accuracy: 0.9872\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.9679\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9872\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.9808\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9936\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9872\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9936\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9936\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9872\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.9936\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 9.6099e-04 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 9.1018e-04 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 8.8498e-04 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6dfb0f7110>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy is 1 i.e. might be overfit:\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG2TiatLyrNf",
        "outputId": "1686894d-f6c8-4d66-f75e-e22f9000511c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0587 - accuracy: 0.7692\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0586843490600586, 0.7692307829856873]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test).reshape(-1)\n",
        "print(y_pred[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR-z3ilXy06P",
        "outputId": "172c2284-fc8b-4fb7-ab20-b6f3189bff79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.2436861e-12 9.6119690e-01 9.9966288e-01 2.5365819e-06 1.0000000e+00\n",
            " 9.9999130e-01 3.2912934e-01 1.0000000e+00 5.1601329e-08 1.0000000e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# round values to nearest 0 or 1:\n",
        "y_pred = np.round(y_pred)\n",
        "print(y_pred[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAiNx4v4zKT3",
        "outputId": "b834e789-0d29-4142-e77d-6b5061199335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 1. 1. 0. 1. 1. 0. 1. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropout:\n",
        "\n",
        "modelDrop = keras.Sequential([\n",
        "        keras.layers.Dense(60, input_dim = 60, activation = 'relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(30, activation = 'relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(15, activation = 'relu'),\n",
        "        keras.layers.Dropout(0.6),\n",
        "        keras.layers.Dense(1, activation = 'sigmoid')                          \n",
        "])\n",
        "\n",
        "modelDrop.compile(loss= 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "TLe4WyWFzZTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelDrop.fit(X_train, y_train, epochs = 100, batch_size = 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlryubDb0EdN",
        "outputId": "3bd09f85-2162-4a39-b1df-fafa21d17ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 2ms/step - loss: 0.7135 - accuracy: 0.5192\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7559 - accuracy: 0.5385\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7094 - accuracy: 0.5321\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7034 - accuracy: 0.4872\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7038 - accuracy: 0.4487\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.5962\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6734 - accuracy: 0.5705\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7078 - accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.5641\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.5577\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7101 - accuracy: 0.5321\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6282\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.5128\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5641\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.5064\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6090\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6435 - accuracy: 0.6154\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.6154\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.5833\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6772 - accuracy: 0.5256\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6154\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5192\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6282\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.6154\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6795\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6474\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.5962\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.6154\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6010 - accuracy: 0.6795\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.6410\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.6795\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.6603\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.6795\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.6859\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.6538\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.7051\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7051\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.6667\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.7115\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5987 - accuracy: 0.7051\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7179\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7436\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7179\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7115\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7244\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7628\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7372\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7821\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7115\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7692\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7372\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7885\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7885\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7692\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8141\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7308\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7949\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7628\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7885\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8013\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7756\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7949\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7949\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7949\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7436\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8013\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.8205\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7885\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8205\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8205\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8205\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8141\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8462\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8205\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7949\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.8205\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8333\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7885\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8526\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8333\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8526\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8205\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8205\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8462\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8654\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8526\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8269\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8205\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8077\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8590\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8462\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8782\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8333\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8654\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.9103\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8782\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8397\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8526\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8397\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8462\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6df083aa50>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here accuracy of training data decreased by using Dropout\n",
        "modelDrop.evaluate(X_test, y_test)\n",
        "# but the accuracy of test data increased"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzesZIp50L-3",
        "outputId": "d5f0187e-6a63-49b1-fe1d-e20299a7c700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.8077\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.40797728300094604, 0.807692289352417]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test).reshape(-1)\n",
        "y_pred = np.round(y_pred)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js08FEo91sde",
        "outputId": "e95759bf-f719-4f70-e854-0decd35e8d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.85      0.79        27\n",
            "           1       0.81      0.68      0.74        25\n",
            "\n",
            "    accuracy                           0.77        52\n",
            "   macro avg       0.78      0.77      0.77        52\n",
            "weighted avg       0.77      0.77      0.77        52\n",
            "\n"
          ]
        }
      ]
    }
  ]
}